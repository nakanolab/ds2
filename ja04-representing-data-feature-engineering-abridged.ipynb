{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from preamble import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4章 データの表現と特徴量エンジニアリング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 カテゴリ変数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1 ワンホットエンコーディング（ダミー変数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [1]\n",
    "import os\n",
    "# The file has no headers naming the columns, so we pass header=None\n",
    "# and provide the column names explicitly in \"names\"\n",
    "adult_path = os.path.join(mglearn.datasets.DATA_PATH, \"adult.data\")\n",
    "data = pd.read_csv(\n",
    "    adult_path, header=None, index_col=False,\n",
    "    names=['age', 'workclass', 'fnlwgt', 'education',  'education-num',\n",
    "           'marital-status', 'occupation', 'relationship', 'race', 'gender',\n",
    "           'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
    "           'income'])\n",
    "# For illustration purposes, we only select some of the columns\n",
    "data = data[['age', 'workclass', 'education', 'gender', 'hours-per-week',\n",
    "             'occupation', 'income']]\n",
    "# IPython.display allows nice output formatting within the Jupyter notebook\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.1.1 文字列で表わされているカテゴリデータのチェック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### [2]\n",
    "print(data.gender.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [3]\n",
    "print(\"Original features:\\n\", list(data.columns), \"\\n\")\n",
    "data_dummies = pd.get_dummies(data)\n",
    "print(\"Features after get_dummies:\\n\", list(data_dummies.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [4]\n",
    "display(data_dummies.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### [5]\n",
    "features = data_dummies.loc[:, 'age':'occupation_ Transport-moving']\n",
    "# Extract NumPy arrays\n",
    "X = features.values\n",
    "y = data_dummies['income_ >50K'].values\n",
    "print(\"X.shape: {}  y.shape: {}\".format(X.shape, y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [6]\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "print(\"Test score: {:.2f}\".format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2 数値でエンコーディングされているカテゴリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [7]\n",
    "# create a DataFrame with an integer feature and a categorical string feature\n",
    "demo_df = pd.DataFrame({'Integer Feature': [0, 1, 2, 1],\n",
    "                        'Categorical Feature': ['socks', 'fox', 'socks', 'box']})\n",
    "display(demo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [8]\n",
    "display(pd.get_dummies(demo_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [9]\n",
    "demo_df['Integer Feature'] = demo_df['Integer Feature'].astype(str)\n",
    "display(pd.get_dummies(demo_df, columns=['Integer Feature', 'Categorical Feature']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit-learn の OneHotEncoder と ColumnTransformer によるカテゴリ変数の前処理\n",
    "このセクションは日本語訳には見当たりません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# Setting sparse=False means OneHotEncode will return a numpy array, not a sparse matrix\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "print(ohe.fit_transform(demo_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ohe.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    [(\"scaling\", StandardScaler(), ['age', 'hours-per-week']),\n",
    "     (\"onehot\", OneHotEncoder(sparse=False), ['workclass', 'education', 'gender', 'occupation'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "# get all columns apart from income for the features\n",
    "data_features = data.drop(\"income\", axis=1)\n",
    "# split dataframe and income\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data_features, data.income, random_state=0)\n",
    "\n",
    "ct.fit(X_train)\n",
    "X_train_trans = ct.transform(X_train)\n",
    "print(X_train_trans.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_trans, y_train)\n",
    "\n",
    "X_test_trans = ct.transform(X_test)\n",
    "print(\"Test score: {:.2f}\".format(logreg.score(X_test_trans, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.named_transformers_.onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ``make_columntransformer`` を使った便利な ColumnTransformer の作成\n",
    "このセクションは日本語訳には見当たりません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "ct = make_column_transformer(\n",
    "    (['age', 'hours-per-week'], StandardScaler()),\n",
    "    (['workclass', 'education', 'gender', 'occupation'], OneHotEncoder(sparse=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 ビニング、離散化、線形モデル、決定木\n",
    "本コースではスキップします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 交互作用と多項式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [10] より必要箇所のみ抜粋\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X, y = mglearn.datasets.make_wave(n_samples=120)\n",
    "line = np.linspace(-3, 3, 1000, endpoint=False).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [20]\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# include polynomials up to x ** 10:\n",
    "# the default \"include_bias=True\" adds a feature that's constantly 1\n",
    "poly = PolynomialFeatures(degree=10, include_bias=False)\n",
    "poly.fit(X)\n",
    "X_poly = poly.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [21]\n",
    "print(\"X_poly.shape: {}\".format(X_poly.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [22]\n",
    "print(\"Entries of X:\\n{}\".format(X[:5]))\n",
    "print(\"Entries of X_poly:\\n{}\".format(X_poly[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### [23]\n",
    "print(\"Polynomial feature names:\\n{}\".format(poly.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [24]\n",
    "reg = LinearRegression().fit(X_poly, y)\n",
    "\n",
    "line_poly = poly.transform(line)\n",
    "plt.plot(line, reg.predict(line_poly), label='polynomial linear regression')\n",
    "plt.plot(X[:, 0], y, 'o', c='k')\n",
    "plt.ylabel(\"Regression output\")\n",
    "plt.xlabel(\"Input feature\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [25]\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "for gamma in [1, 10]:\n",
    "    svr = SVR(gamma=gamma).fit(X, y)\n",
    "    plt.plot(line, svr.predict(line), label='SVR gamma={}'.format(gamma))\n",
    "\n",
    "plt.plot(X[:, 0], y, 'o', c='k')\n",
    "plt.ylabel(\"Regression output\")\n",
    "plt.xlabel(\"Input feature\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [26]\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "boston = load_boston()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    boston.data, boston.target, random_state=0)\n",
    "\n",
    "# rescale data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [27]\n",
    "poly = PolynomialFeatures(degree=2).fit(X_train_scaled)\n",
    "X_train_poly = poly.transform(X_train_scaled)\n",
    "X_test_poly = poly.transform(X_test_scaled)\n",
    "print(\"X_train.shape: {}\".format(X_train.shape))\n",
    "print(\"X_train_poly.shape: {}\".format(X_train_poly.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [28]\n",
    "print(\"Polynomial feature names:\\n{}\".format(poly.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [29]\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge().fit(X_train_scaled, y_train)\n",
    "print(\"Score without interactions: {:.3f}\".format(\n",
    "    ridge.score(X_test_scaled, y_test)))\n",
    "ridge = Ridge().fit(X_train_poly, y_train)\n",
    "print(\"Score with interactions: {:.3f}\".format(\n",
    "    ridge.score(X_test_poly, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [30]\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=100).fit(X_train_scaled, y_train)\n",
    "print(\"Score without interactions: {:.3f}\".format(\n",
    "    rf.score(X_test_scaled, y_test)))\n",
    "rf = RandomForestRegressor(n_estimators=100).fit(X_train_poly, y_train)\n",
    "print(\"Score with interactions: {:.3f}\".format(rf.score(X_test_poly, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 単変量非線形変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [31]\n",
    "rnd = np.random.RandomState(0)\n",
    "X_org = rnd.normal(size=(1000, 3))\n",
    "w = rnd.normal(size=3)\n",
    "\n",
    "X = rnd.poisson(10 * np.exp(X_org))\n",
    "y = np.dot(X_org, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [32]\n",
    "print(\"Number of feature appearances:\\n{}\".format(np.bincount(X[:, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [33]\n",
    "bins = np.bincount(X[:, 0])\n",
    "plt.bar(range(len(bins)), bins, color='grey')\n",
    "plt.ylabel(\"Number of appearances\")\n",
    "plt.xlabel(\"Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [34]\n",
    "from sklearn.linear_model import Ridge\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "score = Ridge().fit(X_train, y_train).score(X_test, y_test)\n",
    "print(\"Test score: {:.3f}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [35]\n",
    "X_train_log = np.log(X_train + 1)\n",
    "X_test_log = np.log(X_test + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### [36]\n",
    "plt.hist(X_train_log[:, 0], bins=25, color='gray')\n",
    "plt.ylabel(\"Number of appearances\")\n",
    "plt.xlabel(\"Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [37]\n",
    "score = Ridge().fit(X_train_log, y_train).score(X_test_log, y_test)\n",
    "print(\"Test score: {:.3f}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 自動特徴量選択\n",
    "#### 4.5.1 単変量統計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [38]\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "# get deterministic random numbers\n",
    "rng = np.random.RandomState(42)\n",
    "noise = rng.normal(size=(len(cancer.data), 50))\n",
    "# add noise features to the data\n",
    "# the first 30 features are from the dataset, the next 50 are noise\n",
    "X_w_noise = np.hstack([cancer.data, noise])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_w_noise, cancer.target, random_state=0, test_size=.5)\n",
    "# use f_classif (the default) and SelectPercentile to select 50% of features\n",
    "select = SelectPercentile(percentile=50)\n",
    "select.fit(X_train, y_train)\n",
    "# transform training set\n",
    "X_train_selected = select.transform(X_train)\n",
    "\n",
    "print(\"X_train.shape: {}\".format(X_train.shape))\n",
    "print(\"X_train_selected.shape: {}\".format(X_train_selected.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [39]\n",
    "mask = select.get_support()\n",
    "print(mask)\n",
    "# visualize the mask. black is True, white is False\n",
    "plt.matshow(mask.reshape(1, -1), cmap='gray_r')\n",
    "plt.xlabel(\"Sample index\")\n",
    "plt.yticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [40]\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# transform test data\n",
    "X_test_selected = select.transform(X_test)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "print(\"Score with all features: {:.3f}\".format(lr.score(X_test, y_test)))\n",
    "lr.fit(X_train_selected, y_train)\n",
    "print(\"Score with only selected features: {:.3f}\".format(\n",
    "    lr.score(X_test_selected, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.2 モデルベース特徴量選択"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [41]\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "select = SelectFromModel(\n",
    "    RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    threshold=\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [42]\n",
    "select.fit(X_train, y_train)\n",
    "X_train_l1 = select.transform(X_train)\n",
    "print(\"X_train.shape: {}\".format(X_train.shape))\n",
    "print(\"X_train_l1.shape: {}\".format(X_train_l1.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [43]\n",
    "mask = select.get_support()\n",
    "# visualize the mask. black is True, white is False\n",
    "plt.matshow(mask.reshape(1, -1), cmap='gray_r')\n",
    "plt.xlabel(\"Sample index\")\n",
    "plt.yticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [44]\n",
    "X_test_l1 = select.transform(X_test)\n",
    "score = LogisticRegression().fit(X_train_l1, y_train).score(X_test_l1, y_test)\n",
    "print(\"Test score: {:.3f}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.3 反復特徴量選択"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [45]\n",
    "from sklearn.feature_selection import RFE\n",
    "select = RFE(RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "             n_features_to_select=40)\n",
    "\n",
    "select.fit(X_train, y_train)\n",
    "# visualize the selected features:\n",
    "mask = select.get_support()\n",
    "plt.matshow(mask.reshape(1, -1), cmap='gray_r')\n",
    "plt.xlabel(\"Sample index\")\n",
    "plt.yticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [46]\n",
    "X_train_rfe = select.transform(X_train)\n",
    "X_test_rfe = select.transform(X_test)\n",
    "\n",
    "score = LogisticRegression().fit(X_train_rfe, y_train).score(X_test_rfe, y_test)\n",
    "print(\"Test score: {:.3f}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [47]\n",
    "print(\"Test score: {:.3f}\".format(select.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 専門家知識の利用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [48]\n",
    "citibike = mglearn.datasets.load_citibike()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [49]\n",
    "print(\"Citi Bike data:\\n{}\".format(citibike.head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [50]\n",
    "plt.figure(figsize=(10, 3))\n",
    "xticks = pd.date_range(start=citibike.index.min(), end=citibike.index.max(),\n",
    "                       freq='D')\n",
    "plt.xticks(xticks, xticks.strftime(\"%a %m-%d\"), rotation=90, ha=\"left\")\n",
    "plt.plot(citibike, linewidth=1)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Rentals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [51]\n",
    "# extract the target values (number of rentals)\n",
    "y = citibike.values\n",
    "# convert to POSIX time by dividing by 10**9\n",
    "X = citibike.index.astype(\"int64\").values.reshape(-1, 1) // 10**9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [52]\n",
    "# use the first 184 data points for training, the rest for testing\n",
    "n_train = 184\n",
    "\n",
    "# function to evaluate and plot a regressor on a given feature set\n",
    "def eval_on_features(features, target, regressor):\n",
    "    # split the given features into a training and a test set\n",
    "    X_train, X_test = features[:n_train], features[n_train:]\n",
    "    # also split the target array\n",
    "    y_train, y_test = target[:n_train], target[n_train:]\n",
    "    regressor.fit(X_train, y_train)\n",
    "    print(\"Test-set R^2: {:.2f}\".format(regressor.score(X_test, y_test)))\n",
    "    y_pred = regressor.predict(X_test)\n",
    "    y_pred_train = regressor.predict(X_train)\n",
    "    plt.figure(figsize=(10, 3))\n",
    "\n",
    "    plt.xticks(range(0, len(X), 8), xticks.strftime(\"%a %m-%d\"), rotation=90,\n",
    "               ha=\"left\")\n",
    "\n",
    "    plt.plot(range(n_train), y_train, label=\"train\")\n",
    "    plt.plot(range(n_train, len(y_test) + n_train), y_test, '-', label=\"test\")\n",
    "    plt.plot(range(n_train), y_pred_train, '--', label=\"prediction train\")\n",
    "\n",
    "    plt.plot(range(n_train, len(y_test) + n_train), y_pred, '--',\n",
    "             label=\"prediction test\")\n",
    "    plt.legend(loc=(1.01, 0))\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Rentals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [53]\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "eval_on_features(X, y, regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [54]\n",
    "X_hour = citibike.index.hour.values.reshape(-1, 1)\n",
    "eval_on_features(X_hour, y, regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [55]\n",
    "X_hour_week = np.hstack([citibike.index.dayofweek.values.reshape(-1, 1),\n",
    "                         citibike.index.hour.values.reshape(-1, 1)])\n",
    "eval_on_features(X_hour_week, y, regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [56]\n",
    "from sklearn.linear_model import LinearRegression\n",
    "eval_on_features(X_hour_week, y, LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [57]\n",
    "enc = OneHotEncoder()\n",
    "X_hour_week_onehot = enc.fit_transform(X_hour_week).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [58]\n",
    "eval_on_features(X_hour_week_onehot, y, Ridge())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [59]\n",
    "poly_transformer = PolynomialFeatures(degree=2, interaction_only=True,\n",
    "                                      include_bias=False)\n",
    "X_hour_week_onehot_poly = poly_transformer.fit_transform(X_hour_week_onehot)\n",
    "lr = Ridge()\n",
    "eval_on_features(X_hour_week_onehot_poly, y, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [60]\n",
    "hour = [\"%02d:00\" % i for i in range(0, 24, 3)]\n",
    "day = [\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"]\n",
    "features =  day + hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### [61]\n",
    "features_poly = poly_transformer.get_feature_names(features)\n",
    "features_nonzero = np.array(features_poly)[lr.coef_ != 0]\n",
    "coef_nonzero = lr.coef_[lr.coef_ != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [62]\n",
    "plt.figure(figsize=(15, 2))\n",
    "plt.plot(coef_nonzero, 'o')\n",
    "plt.xticks(np.arange(len(coef_nonzero)), features_nonzero, rotation=90)\n",
    "plt.xlabel(\"Feature name\")\n",
    "plt.ylabel(\"Feature magnitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 まとめと展望"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
