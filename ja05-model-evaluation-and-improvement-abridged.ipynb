{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "from preamble import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5章 モデルの評価と改良"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [1]\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# create a synthetic dataset\n",
    "X, y = make_blobs(random_state=0)\n",
    "# split data and labels into a training and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "# instantiate a model and fit it to the training set\n",
    "logreg = LogisticRegression().fit(X_train, y_train)\n",
    "# evaluate the model on the test set\n",
    "print(\"Test set score: {:.2f}\".format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 交差検証\n",
    "交差検証のことを英語では cross validation といいます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "### [2]\n",
    "mglearn.plots.plot_cross_validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.1 scikit-learn での交差検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [3] (added solver='liblinear', multi_class='ovr' to LogisticRegression and cv=3 to cross_val_score)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "iris = load_iris()\n",
    "logreg = LogisticRegression(solver='liblinear', multi_class='ovr')\n",
    "\n",
    "scores = cross_val_score(logreg, iris.data, iris.target, cv=3)\n",
    "print(\"Cross-validation scores: {}\".format(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [4]\n",
    "scores = cross_val_score(logreg, iris.data, iris.target, cv=5)\n",
    "print(\"Cross-validation scores: {}\".format(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [5]\n",
    "print(\"Average cross-validation score: {:.2f}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "res = cross_validate(logreg, iris.data, iris.target, cv=5,\n",
    "                     return_train_score=True)\n",
    "display(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(res)\n",
    "display(res_df)\n",
    "print(\"Mean times and scores:\\n\", res_df.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.2 交差検証の利点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3 層化k分割交差検証と他の戦略\n",
    "本コースではスキップします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [6]\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "print(\"Iris labels:\\n{}\".format(iris.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [15] より必要箇所のみ抜粋\n",
    "# create synthetic dataset\n",
    "X, y = make_blobs(n_samples=12, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 グリッドサーチ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.1 単純なグリッドサーチ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [17]\n",
    "# naive grid search implementation\n",
    "from sklearn.svm import SVC\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris.data, iris.target, random_state=0)\n",
    "print(\"Size of training set: {}   size of test set: {}\".format(\n",
    "      X_train.shape[0], X_test.shape[0]))\n",
    "\n",
    "best_score = 0\n",
    "\n",
    "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "        # for each combination of parameters, train an SVC\n",
    "        svm = SVC(gamma=gamma, C=C)\n",
    "        svm.fit(X_train, y_train)\n",
    "        # evaluate the SVC on the test set\n",
    "        score = svm.score(X_test, y_test)\n",
    "        # if we got a better score, store the score and parameters\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters = {'C': C, 'gamma': gamma}\n",
    "\n",
    "print(\"Best score: {:.2f}\".format(best_score))\n",
    "print(\"Best parameters: {}\".format(best_parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.2 パラメータの過剰適合の危険性と検証セット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "### [18]\n",
    "mglearn.plots.plot_threefold_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [19]\n",
    "from sklearn.svm import SVC\n",
    "# split data into train+validation set and test set\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    iris.data, iris.target, random_state=0)\n",
    "# split train+validation set into training and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_trainval, y_trainval, random_state=1)\n",
    "print(\"Size of training set: {}   size of validation set: {}   size of test set:\"\n",
    "      \" {}\\n\".format(X_train.shape[0], X_valid.shape[0], X_test.shape[0]))\n",
    "\n",
    "best_score = 0\n",
    "\n",
    "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "        # for each combination of parameters, train an SVC\n",
    "        svm = SVC(gamma=gamma, C=C)\n",
    "        svm.fit(X_train, y_train)\n",
    "        # evaluate the SVC on the validation set\n",
    "        score = svm.score(X_valid, y_valid)\n",
    "        # if we got a better score, store the score and parameters\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters = {'C': C, 'gamma': gamma}\n",
    "\n",
    "# rebuild a model on the combined training and validation set,\n",
    "# and evaluate it on the test set\n",
    "svm = SVC(**best_parameters)\n",
    "svm.fit(X_trainval, y_trainval)\n",
    "test_score = svm.score(X_test, y_test)\n",
    "print(\"Best score on validation set: {:.2f}\".format(best_score))\n",
    "print(\"Best parameters: \", best_parameters)\n",
    "print(\"Test set score with best parameters: {:.2f}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.3 交差検証を用いたグリッドサーチ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [20]\n",
    "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "        # for each combination of parameters,\n",
    "        # train an SVC\n",
    "        svm = SVC(gamma=gamma, C=C)\n",
    "        # perform cross-validation\n",
    "        scores = cross_val_score(svm, X_trainval, y_trainval, cv=5)\n",
    "        # compute mean cross-validation accuracy\n",
    "        score = np.mean(scores)\n",
    "        # if we got a better score, store the score and parameters\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters = {'C': C, 'gamma': gamma}\n",
    "# rebuild a model on the combined training and validation set\n",
    "svm = SVC(**best_parameters)\n",
    "svm.fit(X_trainval, y_trainval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "### [21]\n",
    "mglearn.plots.plot_cross_val_selection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "### [22]\n",
    "mglearn.plots.plot_grid_search_overview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [23]\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "print(\"Parameter grid:\\n{}\".format(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [24]\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5,\n",
    "                          return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [25]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris.data, iris.target, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [26]\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [27]\n",
    "print(\"Test set score: {:.2f}\".format(grid_search.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [28]\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [29]\n",
    "print(\"Best estimator:\\n{}\".format(grid_search.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2.3.1 交差検証の結果の解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [30]\n",
    "import pandas as pd\n",
    "# convert to Dataframe\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "# show the first 5 rows\n",
    "display(results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [31]\n",
    "scores = np.array(results.mean_test_score).reshape(6, 6)\n",
    "\n",
    "# plot the mean cross-validation scores\n",
    "mglearn.tools.heatmap(scores, xlabel='gamma', xticklabels=param_grid['gamma'],\n",
    "                      ylabel='C', yticklabels=param_grid['C'], cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### [32]\n",
    "fig, axes = plt.subplots(1, 3, figsize=(13, 5))\n",
    "\n",
    "param_grid_linear = {'C': np.linspace(1, 2, 6),\n",
    "                     'gamma':  np.linspace(1, 2, 6)}\n",
    "\n",
    "param_grid_one_log = {'C': np.linspace(1, 2, 6),\n",
    "                      'gamma':  np.logspace(-3, 2, 6)}\n",
    "\n",
    "param_grid_range = {'C': np.logspace(-3, 2, 6),\n",
    "                    'gamma':  np.logspace(-7, -2, 6)}\n",
    "\n",
    "for param_grid, ax in zip([param_grid_linear, param_grid_one_log,\n",
    "                           param_grid_range], axes):\n",
    "    grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    scores = grid_search.cv_results_['mean_test_score'].reshape(6, 6)\n",
    "\n",
    "    # plot the mean cross-validation scores\n",
    "    scores_image = mglearn.tools.heatmap(\n",
    "        scores, xlabel='gamma', ylabel='C', xticklabels=param_grid['gamma'],\n",
    "        yticklabels=param_grid['C'], cmap=\"viridis\", ax=ax)\n",
    "\n",
    "plt.colorbar(scores_image, ax=axes.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2.3.2 グリッドでないサーチ空間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [33]\n",
    "param_grid = [{'kernel': ['rbf'],\n",
    "               'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "               'gamma': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
    "              {'kernel': ['linear'],\n",
    "               'C': [0.001, 0.01, 0.1, 1, 10, 100]}]\n",
    "print(\"List of grids:\\n{}\".format(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [34]\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5,\n",
    "                          return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [35]\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "# we display the transposed table so that it better fits on the page:\n",
    "display(results.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.3.3 異なる交差検証手法を用いたグリッドサーチ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.3.4 ネストした交差検証\n",
    "本コースではスキップします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 交差検証とグリッドサーチの並列化\n",
    "GridSearchCV のパラメータで n_jobs を指定する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 評価基準とスコア\n",
    "#### 5.3.1 最終的な目標を見失わないこと"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.2 2クラス分類における基準\n",
    "##### 5.3.2.1 エラーの種類\n",
    "##### 5.3.2.2 偏ったデータセット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [39]\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "y = digits.target == 9\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    digits.data, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [40]\n",
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_majority = DummyClassifier(strategy='most_frequent').fit(X_train, y_train)\n",
    "pred_most_frequent = dummy_majority.predict(X_test)\n",
    "print(\"Unique predicted labels: {}\".format(np.unique(pred_most_frequent)))\n",
    "print(\"Test score: {:.2f}\".format(dummy_majority.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [41]\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(max_depth=2).fit(X_train, y_train)\n",
    "pred_tree = tree.predict(X_test)\n",
    "print(\"Test score: {:.2f}\".format(tree.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [42]\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "dummy = DummyClassifier().fit(X_train, y_train)\n",
    "pred_dummy = dummy.predict(X_test)\n",
    "print(\"dummy score: {:.2f}\".format(dummy.score(X_test, y_test)))\n",
    "\n",
    "logreg = LogisticRegression(C=0.1).fit(X_train, y_train)\n",
    "pred_logreg = logreg.predict(X_test)\n",
    "print(\"logreg score: {:.2f}\".format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.3.2.3 混同行列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [43]\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion = confusion_matrix(y_test, pred_logreg)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [44]\n",
    "mglearn.plots.plot_confusion_matrix_illustration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [45]\n",
    "mglearn.plots.plot_binary_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [46]\n",
    "print(\"Most frequent class:\")\n",
    "print(confusion_matrix(y_test, pred_most_frequent))\n",
    "print(\"\\nDummy model:\")\n",
    "print(confusion_matrix(y_test, pred_dummy))\n",
    "print(\"\\nDecision tree:\")\n",
    "print(confusion_matrix(y_test, pred_tree))\n",
    "print(\"\\nLogistic Regression\")\n",
    "print(confusion_matrix(y_test, pred_logreg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 精度との関係\n",
    "\\begin{equation}\n",
    "\\text{精度: Accuracy} = \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{TN} + \\text{FP} + \\text{FN}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 適合率、再現率、f-値\n",
    "\\begin{equation}\n",
    "\\text{適合率: Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "\\begin{equation}\n",
    "\\text{再現率: Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\text{F} = 2 \\cdot \\frac{\\text{precision} \\cdot \\text{recall}}{\\text{precision} + \\text{recall}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [47]\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"f1 score most frequent: {:.2f}\".format(\n",
    "    f1_score(y_test, pred_most_frequent)))\n",
    "print(\"f1 score dummy: {:.2f}\".format(f1_score(y_test, pred_dummy)))\n",
    "print(\"f1 score tree: {:.2f}\".format(f1_score(y_test, pred_tree)))\n",
    "print(\"f1 score logistic regression: {:.2f}\".format(\n",
    "    f1_score(y_test, pred_logreg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [48]\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, pred_most_frequent,\n",
    "                            target_names=[\"not nine\", \"nine\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [49]\n",
    "print(classification_report(y_test, pred_dummy,\n",
    "                            target_names=[\"not nine\", \"nine\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [50]\n",
    "print(classification_report(y_test, pred_logreg,\n",
    "                            target_names=[\"not nine\", \"nine\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.3.2.4 不確実性を考慮に入れる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [51]\n",
    "X, y = make_blobs(n_samples=(400, 50), cluster_std=[7.0, 2],\n",
    "                  random_state=22)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "svc = SVC(gamma=.05).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [52]\n",
    "mglearn.plots.plot_decision_threshold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [53]\n",
    "print(classification_report(y_test, svc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [54]\n",
    "y_pred_lower_threshold = svc.decision_function(X_test) > -.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [55]\n",
    "print(classification_report(y_test, y_pred_lower_threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.3.2.5 適合率・再現率カーブと ROC カーブ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [56]\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "precision, recall, thresholds = precision_recall_curve(\n",
    "    y_test, svc.decision_function(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [57]\n",
    "# Use more data points for a smoother curve\n",
    "X, y = make_blobs(n_samples=(4000, 500), cluster_std=[7.0, 2], random_state=22)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "svc = SVC(gamma=.05).fit(X_train, y_train)\n",
    "precision, recall, thresholds = precision_recall_curve(\n",
    "    y_test, svc.decision_function(X_test))\n",
    "# find threshold closest to zero\n",
    "close_zero = np.argmin(np.abs(thresholds))\n",
    "plt.plot(precision[close_zero], recall[close_zero], 'o', markersize=10,\n",
    "         label=\"threshold zero\", fillstyle=\"none\", c='k', mew=2)\n",
    "\n",
    "plt.plot(precision, recall, label=\"precision recall curve\")\n",
    "plt.xlabel(\"Precision\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [58]\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=0, max_features=2)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# RandomForestClassifier has predict_proba, but not decision_function\n",
    "precision_rf, recall_rf, thresholds_rf = precision_recall_curve(\n",
    "    y_test, rf.predict_proba(X_test)[:, 1])\n",
    "\n",
    "plt.plot(precision, recall, label=\"svc\")\n",
    "\n",
    "plt.plot(precision[close_zero], recall[close_zero], 'o', markersize=10,\n",
    "         label=\"threshold zero svc\", fillstyle=\"none\", c='k', mew=2)\n",
    "\n",
    "plt.plot(precision_rf, recall_rf, label=\"rf\")\n",
    "\n",
    "close_default_rf = np.argmin(np.abs(thresholds_rf - 0.5))\n",
    "plt.plot(precision_rf[close_default_rf], recall_rf[close_default_rf], '^', c='k',\n",
    "         markersize=10, label=\"threshold 0.5 rf\", fillstyle=\"none\", mew=2)\n",
    "plt.xlabel(\"Precision\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [59]\n",
    "print(\"f1_score of random forest: {:.3f}\".format(\n",
    "    f1_score(y_test, rf.predict(X_test))))\n",
    "print(\"f1_score of svc: {:.3f}\".format(f1_score(y_test, svc.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [60]\n",
    "from sklearn.metrics import average_precision_score\n",
    "ap_rf = average_precision_score(y_test, rf.predict_proba(X_test)[:, 1])\n",
    "ap_svc = average_precision_score(y_test, svc.decision_function(X_test))\n",
    "print(\"Average precision of random forest: {:.3f}\".format(ap_rf))\n",
    "print(\"Average precision of svc: {:.3f}\".format(ap_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.3.2.6 受信者動作特性 (ROC) と AUC\n",
    "\\begin{equation}\n",
    "\\text{偽陽性率: FPR} = \\frac{\\text{FP}}{\\text{FP} + \\text{TN}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [61]\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, svc.decision_function(X_test))\n",
    "\n",
    "plt.plot(fpr, tpr, label=\"ROC Curve\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR (recall)\")\n",
    "# find threshold closest to zero\n",
    "close_zero = np.argmin(np.abs(thresholds))\n",
    "plt.plot(fpr[close_zero], tpr[close_zero], 'o', markersize=10,\n",
    "         label=\"threshold zero\", fillstyle=\"none\", c='k', mew=2)\n",
    "plt.legend(loc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [62]\n",
    "fpr_rf, tpr_rf, thresholds_rf = roc_curve(y_test, rf.predict_proba(X_test)[:, 1])\n",
    "\n",
    "plt.plot(fpr, tpr, label=\"ROC Curve SVC\")\n",
    "plt.plot(fpr_rf, tpr_rf, label=\"ROC Curve RF\")\n",
    "\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR (recall)\")\n",
    "plt.plot(fpr[close_zero], tpr[close_zero], 'o', markersize=10,\n",
    "         label=\"threshold zero SVC\", fillstyle=\"none\", c='k', mew=2)\n",
    "close_default_rf = np.argmin(np.abs(thresholds_rf - 0.5))\n",
    "plt.plot(fpr_rf[close_default_rf], tpr[close_default_rf], '^', markersize=10,\n",
    "         label=\"threshold 0.5 RF\", fillstyle=\"none\", c='k', mew=2)\n",
    "\n",
    "plt.legend(loc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [63]\n",
    "from sklearn.metrics import roc_auc_score\n",
    "rf_auc = roc_auc_score(y_test, rf.predict_proba(X_test)[:, 1])\n",
    "svc_auc = roc_auc_score(y_test, svc.decision_function(X_test))\n",
    "print(\"AUC for Random Forest: {:.3f}\".format(rf_auc))\n",
    "print(\"AUC for SVC: {:.3f}\".format(svc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [64] (modified gamma=0.05 -> gamma=0.1)\n",
    "y = digits.target == 9\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    digits.data, y, random_state=0)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for gamma in [1, 0.1, 0.01]:\n",
    "    svc = SVC(gamma=gamma).fit(X_train, y_train)\n",
    "    accuracy = svc.score(X_test, y_test)\n",
    "    auc = roc_auc_score(y_test, svc.decision_function(X_test))\n",
    "    fpr, tpr, _ = roc_curve(y_test , svc.decision_function(X_test))\n",
    "    print(\"gamma = {:.2f}  accuracy = {:.2f}  AUC = {:.2f}\".format(\n",
    "          gamma, accuracy, auc))\n",
    "    plt.plot(fpr, tpr, label=\"gamma={:.3f}\".format(gamma))\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.xlim(-0.01, 1)\n",
    "plt.ylim(0, 1.02)\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.3 多クラス分類の基準"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [65]\n",
    "from sklearn.metrics import accuracy_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    digits.data, digits.target, random_state=0)\n",
    "lr = LogisticRegression().fit(X_train, y_train)\n",
    "pred = lr.predict(X_test)\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy_score(y_test, pred)))\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion_matrix(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "### [66]\n",
    "scores_image = mglearn.tools.heatmap(\n",
    "    confusion_matrix(y_test, pred), xlabel='Predicted label',\n",
    "    ylabel='True label', xticklabels=digits.target_names,\n",
    "    yticklabels=digits.target_names, cmap=plt.cm.gray_r, fmt=\"%d\")\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "《参考》seaborn を使った混同行列の可視化。あらかじめ ``conda install seaborn`` しておく必要あり。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df = pd.DataFrame(confusion_matrix(y_test, pred), index=digits.target_names, columns=digits.target_names)\n",
    "df.index.name = 'True label'\n",
    "df.columns.name = 'Predicted label'\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.set(font_scale=1.2)\n",
    "ax = sns.heatmap(df, annot=True, annot_kws={'size': 10})\n",
    "# workaround for matplotlib 3.1.1 (cf. https://stackoverflow.com/questions/56942670/)\n",
    "high, low = ax.get_ylim()\n",
    "ax.set_ylim((high + 0.5, low - 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [67]\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [68]\n",
    "print(\"Micro average f1 score: {:.3f}\".format(\n",
    "    f1_score(y_test, pred, average=\"micro\")))\n",
    "print(\"Macro average f1 score: {:.3f}\".format(\n",
    "    f1_score(y_test, pred, average=\"macro\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.4 回帰の基準"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.5 評価基準を用いたモデル選択"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [69] (added gamma='auto' to SVC)\n",
    "# default scoring for classification is accuracy\n",
    "print(\"Default scoring: {}\".format(\n",
    "    cross_val_score(SVC(gamma='auto'), digits.data, digits.target == 9, cv=5)))\n",
    "# providing scoring=\"accuracy\" doesn't change the results\n",
    "explicit_accuracy =  cross_val_score(SVC(gamma='auto'), digits.data, digits.target == 9,\n",
    "                                     scoring=\"accuracy\", cv=5)\n",
    "print(\"Explicit accuracy scoring: {}\".format(explicit_accuracy))\n",
    "roc_auc =  cross_val_score(SVC(gamma='auto'), digits.data, digits.target == 9,\n",
    "                           scoring=\"roc_auc\", cv=5)\n",
    "print(\"AUC scoring: {}\".format(roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = cross_validate(SVC(gamma='auto'), digits.data, digits.target == 9,\n",
    "                     scoring=[\"accuracy\", \"roc_auc\", \"recall_macro\"],\n",
    "                     return_train_score=True, cv=5)\n",
    "display(pd.DataFrame(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [70] (added gamma='auto' to SVC)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    digits.data, digits.target == 9, random_state=0)\n",
    "\n",
    "# we provide a somewhat bad grid to illustrate the point:\n",
    "param_grid = {'gamma': [0.0001, 0.01, 0.1, 1, 10]}\n",
    "# using the default scoring of accuracy:\n",
    "grid = GridSearchCV(SVC(gamma='auto'), param_grid=param_grid)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Grid-Search with accuracy\")\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best cross-validation score (accuracy)): {:.3f}\".format(grid.best_score_))\n",
    "print(\"Test set AUC: {:.3f}\".format(\n",
    "    roc_auc_score(y_test, grid.decision_function(X_test))))\n",
    "print(\"Test set accuracy: {:.3f}\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [71] (added gamma='auto' to SVC)\n",
    "# using AUC scoring instead:\n",
    "grid = GridSearchCV(SVC(gamma='auto'), param_grid=param_grid, scoring=\"roc_auc\")\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"\\nGrid-Search with AUC\")\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best cross-validation score (AUC): {:.3f}\".format(grid.best_score_))\n",
    "print(\"Test set AUC: {:.3f}\".format(\n",
    "    roc_auc_score(y_test, grid.decision_function(X_test))))\n",
    "print(\"Test set accuracy: {:.3f}\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [72]\n",
    "from sklearn.metrics.scorer import SCORERS\n",
    "print(\"Available scorers:\")\n",
    "print(sorted(SCORERS.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 まとめと展望"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
